<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> DOTIE | Manish Nagaraj </title> <meta name="author" content="Manish Nagaraj"> <meta name="description" content="Detecting Objects through Temporal Isolation of Events"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://manishnagaraj.github.io/projects/Dotie/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Manish</span> Nagaraj </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">DOTIE</h1> <p class="post-description">Detecting Objects through Temporal Isolation of Events</p> </header> <article> <h2 id="motivation">Motivation</h2> <p>Vision-based autonomous navigation systems necessitate fast and accurate object detection algorithms that are computationally efficient due to the limited energy resources of deployment hardware. Biologically inspired event cameras offer a promising solution as vision sensors due to their inherent advantages like high speed, energy efficiency, low latency, and robustness to varied lighting conditions. However, traditional computer vision algorithms often falter with event-based outputs because these outputs lack standard photometric features like light intensity and texture. This challenge motivates the exploration of temporal features inherently present in events, which are often overlooked by conventional algorithms. DOTIE (Detecting Objects through Temporal Isolation of Events) was developed to leverage this temporal information to efficiently detect moving objects using a lightweight spiking neural architecture.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DOTIE_GA-480.webp 480w,/assets/img/publication_preview/DOTIE_GA-800.webp 800w,/assets/img/publication_preview/DOTIE_GA-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/publication_preview/DOTIE_GA.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Motivation for DOTIE" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="overview-of-architecture">Overview of Architecture</h2> <p>DOTIE employs a novel technique that capitalizes on the temporal information inherent in event data to detect moving objects. The core of DOTIE is a lightweight, single-layer spiking neural network (SNN) designed to separate events based on the speed of the objects that generated them.</p> <p>The fundamental principles behind the architecture are:</p> <ul> <li>Events generated by the same object are temporally close to each other.</li> <li>Events generated by the same object are spatially close to each other.</li> </ul> <div class="row justify-content-sm-center align-items-center"> <div class="col-sm-6 mt-3 mt-md-0"> <p>The architecture utilizes Leaky Integrate and Fire (LIF) neurons, which are sensitive to the temporal structure of input events. By tuning hyperparameters like the threshold and leak factor, these neurons can identify input spikes (events) that occur close together in time, effectively filtering events based on object speed. Instead of connecting each pixel directly to a neuron, DOTIE uses a weighted sum from a neighborhood of pixels (e.g., 3x3) as input to each neuron. This allows the SNN to better identify fast-moving objects by considering the spatio-temporal pattern of events.</p> </div> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DOTIE_project/LiF-480.webp 480w,/assets/img/DOTIE_project/LiF-800.webp 800w,/assets/img/DOTIE_project/LiF-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DOTIE_project/LiF.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="LIF Neuron Behavior" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Explanation of LIF neuron usage in DOTIE. Right: Visualization of Leaky Integrate and Fire (LIF) neuron dynamics. </div> <p>The key advantages of this architecture include:</p> <ul> <li>Asynchronous operation, processing events as they are generated.</li> <li>Robustness to camera noise and events from static background objects.</li> <li>Low latency and energy overhead due to the single-layer SNN and the nature of spiking neuron operations (accumulate vs. multiply-and-accumulate).</li> <li>Scene independence, meaning the SNN parameters correspond to object speeds and can be fine-tuned before deployment without extensive retraining for new scenes.</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DOTIE_project/visualization_of_dotie-480.webp 480w,/assets/img/DOTIE_project/visualization_of_dotie-800.webp 800w,/assets/img/DOTIE_project/visualization_of_dotie-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DOTIE_project/visualization_of_dotie.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="DOTIE visualization" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Visualization of DOTIE in action. </div> <h2 id="results-and-demonstration">Results and Demonstration</h2> <p>DOTIE has demonstrated its capability to effectively detect the speed of objects using only event data. In a practical demonstration mentioned in the literature, a DAVIS346 Event Camera was used to capture events from a disk rotating at three different speeds (slow, medium, and fast) on an electric motor. The spiking architecture was fine-tuned to separate events corresponding to these speeds, visually represented by color-coding events based on their allocated speed bin.</p> <p>To further validate DOTIE’s real-time capabilities, a live demonstration was conducted using an Arduino board to control the rotation speed of a disk at three distinct levels. A DVS (Dynamic Vision Sensor) event camera captured the asynchronous events generated by the rotating disk, and DOTIE was applied in real-time to process this event stream. The results of this demonstration are visualized below, showcasing DOTIE’s ability to track the moving disk.</p> <div class="row justify-content-sm-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DOTIE_project/setup-480.webp 480w,/assets/img/DOTIE_project/setup-800.webp 800w,/assets/img/DOTIE_project/setup-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DOTIE_project/setup.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Live Demo Setup" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DOTIE_project/Large_circle-480.webp 480w,/assets/img/DOTIE_project/Large_circle-800.webp 800w,/assets/img/DOTIE_project/Large_circle-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DOTIE_project/Large_circle.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Live DOTIE Output" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Experimental setup for the live DOTIE demonstration with a rotating disk controlled by an Arduino. Right: Output of the live DOTIE processing, visualizing the tracking of the rotating disk. </div> <p><strong>Accuracy:</strong> Compared to other event-based detection algorithms on the MVSEC dataset (outdoor day 2 segment), DOTIE (combined with DBSCAN for clustering) achieved significantly higher performance:</p> <ul> <li> <strong>Mean IoU:</strong> 0.8593</li> <li> <strong>Recall:</strong> 1.00</li> <li> <strong>Precision:</strong> 1.00 This outperforms methods like GMM, Meanshift, K-Means, GSCE, and DBSCAN alone, which struggled with background noise and accurately delineating moving objects.</li> </ul> <p><strong>Computational Efficiency:</strong> A key highlight of DOTIE is its energy efficiency, particularly when implemented on neuromorphic hardware.</p> <ul> <li>When implemented on <strong>Intel Loihi-2</strong>, DOTIE showed a dynamic energy consumption of <strong>2.32 mJ per inference</strong>, compared to <strong>28.74 mJ per inference on a CPU</strong>. This represents a <strong>14x reduction in energy consumption</strong>.</li> <li>The estimated energy for the spiking layer during inference on the MVSEC outdoor day 2 segment was approximately <strong>11.03nJ</strong>. This is a substantial reduction compared to traditional artificial neural networks like YOLOv3, which was estimated to consume around 44.06mJ for inference on the same dataset.</li> <li>While the CPU implementation achieved higher Frames Per Second (946 FPS) than Loihi-2 (266 FPS) in one reported experiment, the significant energy savings on neuromorphic hardware underscore its suitability for power-constrained applications.</li> </ul> <p>The algorithm is asynchronous and can operate at the rate events are generated, minimizing processing overhead in terms of latency. A bounding-box IoU score of roughly 80% was achieved between the Loihi (Lava simulator) and CPU (PyTorch) implementations on a subset of the MVSEC dataset.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DOTIE_project/DOTIE_Loihi_CPU_comparison-480.webp 480w,/assets/img/DOTIE_project/DOTIE_Loihi_CPU_comparison-800.webp 800w,/assets/img/DOTIE_project/DOTIE_Loihi_CPU_comparison-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DOTIE_project/DOTIE_Loihi_CPU_comparison.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Loihi vs CPU Spikes/Bounding Box" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Comparison of spike generation and bounding box output between Loihi (Lava) and CPU (PyTorch) implementations on an example frame from the MVSEC dataset. </div> <p>This project showcases the advantages of using event cameras combined with spiking neural networks and neuromorphic hardware for efficient and low-latency object detection. You can find details in <a class="citation" href="#nagaraj2023dotie">(Nagaraj et al., 2023)</a> and <a class="citation" href="#roy2023live">(Roy et al., 2023)</a>.</p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/DOTIE_visual.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DOTIE_visual.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nagaraj2023dotie" class="col-sm-8"> <div class="title">Dotie-detecting objects through temporal isolation of events using a spiking architecture</div> <div class="author"> <em>Manish Nagaraj</em>, Chamika Mihiranga Liyanagedera, and Kaushik Roy </div> <div class="periodical"> <em>In 2023 IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ICRA48891.2023.10161164" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://www.youtube.com/watch?v=PuJKQlXoyMk" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/manishnagaraj/DOTIE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Vision-based autonomous navigation systems rely on fast and accurate object detection algorithms to avoid obstacles. Algorithms and sensors designed for such systems need to be computationally efficient, due to the limited energy of the hardware used for deployment. Biologically inspired event cameras are a good candidate as a vision sensor for such systems due to their speed, energy efficiency, and robustness to varying lighting conditions. However, traditional computer vision algorithms fail to work on event-based outputs, as they lack photometric features such as light intensity and texture. In this work, we propose a novel technique that utilizes the temporal information inherently present in the events to efficiently detect moving objects. Our technique consists of a lightweight spiking neural architecture that is able to separate events based on the speed of the corresponding objects. These separated events are then further grouped spatially to determine object boundaries. This method of object detection is both asynchronous and robust to camera noise. In addition, it shows good performance in scenarios with events generated by static objects in the background, where existing event-based algorithms fail. We show that by utilizing our architecture, autonomous navigation systems can have minimal latency and energy overheads for performing object detection.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/DOTIE_GA.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DOTIE_GA.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="roy2023live" class="col-sm-8"> <div class="title">Live demonstration: Real-time event-based speed detection using spiking neural networks</div> <div class="author"> Arjun Roy, <em>Manish Nagaraj</em>, Chamika Mihiranga Liyanagedera, and Kaushik Roy </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR Workshops)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/manishnagaraj/DOTIE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Event cameras are emerging as an ideal vision sensor for high-speed applications due to their low latency and power consumption. DOTIE, a recent work in literature, has proposed a method to detect objects through spatial and temporal isolation of events with a spiking neural network. In this work, we implement DOTIE to detect a disk moving in a circular motion and identify the speed of rotation. We further validate the claim that spiking architectures can efficiently handle events by implementing DOTIE on Intel Loihi, a neuromorphic hardware suitable for spiking neural networks, and reveal a 14× reduction in energy consumption compared to the CPU implementation of DOTIE.</p> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Manish Nagaraj. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>